{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "febaed7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1️⃣ Imports\n",
    "# ===========================\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import arviz as az\n",
    "import pymc as pm\n",
    "import aesara.tensor as at\n",
    "import plotly.graph_objects as go\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Suppress BLAS and other numerical warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d12bb61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Ensure we can import from src\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "from data_preprocessing import load_and_preprocess_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0515e7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 2️⃣ Load Data\n",
    "# ===========================\n",
    "data_path = \"../data/raw/BrentOilPrices.csv\"\n",
    "events_path = \"../data/events.csv\"\n",
    "\n",
    "df = load_and_preprocess_data(data_path)\n",
    "df['Log_Return'] = np.log(df['Price']) - np.log(df['Price'].shift(1))\n",
    "data = df['Log_Return'].dropna().values\n",
    "n = len(data)\n",
    "idx = np.arange(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaa54c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Cannot convert spacings to a tensor variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m pm.Model() \u001b[38;5;28;01mas\u001b[39;00m model:\n\u001b[32m      6\u001b[39m     spacings = pm.Exponential(\u001b[33m\"\u001b[39m\u001b[33mspacings\u001b[39m\u001b[33m\"\u001b[39m, lam=\u001b[32m1.0\u001b[39m, shape=k)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     taus_float = pm.Deterministic(\u001b[33m\"\u001b[39m\u001b[33mtaus_float\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcumsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspacings\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m      8\u001b[39m     taus = pm.Deterministic(\u001b[33m\"\u001b[39m\u001b[33mtaus\u001b[39m\u001b[33m\"\u001b[39m, taus_float / at.sum(spacings) * (n - \u001b[32m1\u001b[39m))\n\u001b[32m     10\u001b[39m     mus = pm.Normal(\u001b[33m\"\u001b[39m\u001b[33mmus\u001b[39m\u001b[33m\"\u001b[39m, mu=\u001b[32m0\u001b[39m, sigma=\u001b[32m1\u001b[39m, shape=k + \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\10x AIMastery\\brent-oil-change-analysis\\venv\\Lib\\site-packages\\aesara\\tensor\\extra_ops.py:430\u001b[39m, in \u001b[36mcumsum\u001b[39m\u001b[34m(x, axis)\u001b[39m\n\u001b[32m    413\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcumsum\u001b[39m(x, axis=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    414\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the cumulative sum of the elements along a given `axis`.\u001b[39;00m\n\u001b[32m    415\u001b[39m \n\u001b[32m    416\u001b[39m \u001b[33;03m    This wraps ``numpy.cumsum``.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    428\u001b[39m \n\u001b[32m    429\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCumOp\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43madd\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\10x AIMastery\\brent-oil-change-analysis\\venv\\Lib\\site-packages\\aesara\\graph\\op.py:295\u001b[39m, in \u001b[36mOp.__call__\u001b[39m\u001b[34m(self, *inputs, **kwargs)\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Construct an `Apply` node using :meth:`Op.make_node` and return its outputs.\u001b[39;00m\n\u001b[32m    254\u001b[39m \n\u001b[32m    255\u001b[39m \u001b[33;03mThis method is just a wrapper around :meth:`Op.make_node`.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    292\u001b[39m \n\u001b[32m    293\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    294\u001b[39m return_list = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mreturn_list\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m node = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmake_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config.compute_test_value != \u001b[33m\"\u001b[39m\u001b[33moff\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    298\u001b[39m     compute_test_value(node)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\10x AIMastery\\brent-oil-change-analysis\\venv\\Lib\\site-packages\\aesara\\tensor\\extra_ops.py:301\u001b[39m, in \u001b[36mCumOp.make_node\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    300\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmake_node\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m301\u001b[39m     x = \u001b[43mat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mas_tensor_variable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    302\u001b[39m     out_type = x.type()\n\u001b[32m    304\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\10x AIMastery\\brent-oil-change-analysis\\venv\\Lib\\site-packages\\aesara\\tensor\\__init__.py:49\u001b[39m, in \u001b[36mas_tensor_variable\u001b[39m\u001b[34m(x, name, ndim, **kwargs)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mas_tensor_variable\u001b[39m(\n\u001b[32m     18\u001b[39m     x: TensorLike, name: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m, ndim: Optional[\u001b[38;5;28mint\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m, **kwargs\n\u001b[32m     19\u001b[39m ) -> \u001b[33m\"\u001b[39m\u001b[33mTensorVariable\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     20\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Convert `x` into an equivalent `TensorVariable`.\u001b[39;00m\n\u001b[32m     21\u001b[39m \n\u001b[32m     22\u001b[39m \u001b[33;03m    This function can be used to turn ndarrays, numbers, `ScalarType` instances,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     47\u001b[39m \n\u001b[32m     48\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_as_tensor_variable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python311\\Lib\\functools.py:909\u001b[39m, in \u001b[36msingledispatch.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    905\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[32m    906\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requires at least \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    907\u001b[39m                     \u001b[33m'\u001b[39m\u001b[33m1 positional argument\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m909\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\10x AIMastery\\brent-oil-change-analysis\\venv\\Lib\\site-packages\\aesara\\tensor\\__init__.py:56\u001b[39m, in \u001b[36m_as_tensor_variable\u001b[39m\u001b[34m(x, name, ndim, **kwargs)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;129m@singledispatch\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_as_tensor_variable\u001b[39m(\n\u001b[32m     54\u001b[39m     x: TensorLike, name: Optional[\u001b[38;5;28mstr\u001b[39m], ndim: Optional[\u001b[38;5;28mint\u001b[39m], **kwargs\n\u001b[32m     55\u001b[39m ) -> \u001b[33m\"\u001b[39m\u001b[33mTensorVariable\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot convert \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m to a tensor variable.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNotImplementedError\u001b[39m: Cannot convert spacings to a tensor variable."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pymc as pm\n",
    "import matplotlib.pyplot as plt\n",
    "import arviz as az\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import aesara.tensor as at\n",
    "from scipy.stats import ttest_ind\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "def load_and_preprocess_data(filepath):\n",
    "    \"\"\"Load and preprocess Brent oil price data.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "        df['Price'] = pd.to_numeric(df['Price'], errors='coerce')\n",
    "        df = df.dropna()\n",
    "        print(f\"Loaded data with {len(df)} records\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Data loading failed: {e}\")\n",
    "\n",
    "def quantify_event_impact(df, change_index, window=30):\n",
    "    \"\"\"Quantify impact of change point on oil prices.\"\"\"\n",
    "    start = max(0, change_index - window)\n",
    "    end = min(len(df) - 1, change_index + window)\n",
    "\n",
    "    before = df['Price'].iloc[start:change_index]\n",
    "    after = df['Price'].iloc[change_index:end]\n",
    "\n",
    "    return {\n",
    "        \"mean_change\": after.mean() - before.mean(),\n",
    "        \"volatility_change\": after.std() - before.std(),\n",
    "        \"pct_price_change\": ((after.mean() - before.mean()) / before.mean()) * 100,\n",
    "        \"t_test_pvalue\": ttest_ind(before, after, equal_var=False).pvalue\n",
    "    }\n",
    "\n",
    "def bayesian_multiple_change_point_model(filepath: str, events_filepath: str, k=3):\n",
    "    \"\"\"Bayesian model with k change points for Brent oil data.\"\"\"\n",
    "    try:\n",
    "        # Load and preprocess data\n",
    "        df = load_and_preprocess_data(filepath)\n",
    "        df['Log_Return'] = np.log(df['Price']) - np.log(df['Price'].shift(1))\n",
    "        data = df['Log_Return'].dropna().values\n",
    "        n = len(data)\n",
    "        \n",
    "        if len(data) < k + 1:\n",
    "            raise ValueError(f\"Data length ({len(data)}) too short for {k} change points.\")\n",
    "        \n",
    "        print(f\"Analyzing {n} data points with {k} change points\")\n",
    "\n",
    "        with pm.Model() as model:\n",
    "            # Define k ordered change points\n",
    "            tau = pm.Uniform(\n",
    "                \"tau\",\n",
    "                lower=np.zeros(k),\n",
    "                upper=np.ones(k)*n,\n",
    "                shape=k,\n",
    "                transform=pm.distributions.transforms.Ordered(),\n",
    "                initval=np.linspace(n*0.2, n*0.8, k)\n",
    "            )\n",
    "            \n",
    "            # Segment parameters\n",
    "            mu = pm.Normal(\"mu\", mu=0, sigma=1, shape=k+1)\n",
    "            sigma = pm.HalfNormal(\"sigma\", sigma=1)\n",
    "            \n",
    "            # Piecewise mean construction using switch\n",
    "            segment_means = at.zeros(n)\n",
    "            for i in range(k+1):\n",
    "                if i == 0:\n",
    "                    condition = at.lt(at.arange(n), tau[0])\n",
    "                elif i == k:\n",
    "                    condition = at.ge(at.arange(n), tau[-1])\n",
    "                else:\n",
    "                    condition = at.and_(at.ge(at.arange(n), tau[i-1]),\n",
    "                                      at.lt(at.arange(n), tau[i]))\n",
    "                \n",
    "                segment_means = at.set_subtensor(\n",
    "                    segment_means[condition],\n",
    "                    mu[i]\n",
    "                )\n",
    "            \n",
    "            # Likelihood\n",
    "            obs = pm.Normal(\"obs\", mu=segment_means, sigma=sigma, observed=data)\n",
    "            \n",
    "            # Sampling\n",
    "            trace = pm.sample(\n",
    "                1000,\n",
    "                tune=1000,\n",
    "                target_accept=0.9,\n",
    "                return_inferencedata=True,\n",
    "                cores=1\n",
    "            )\n",
    "            \n",
    "            # Posterior predictive\n",
    "            ppc = pm.sample_posterior_predictive(trace, var_names=[\"obs\"])\n",
    "\n",
    "        # Analysis and visualization\n",
    "        analyze_results(trace, df, ppc, events_filepath, k)\n",
    "        \n",
    "        return trace, df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Model execution failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def analyze_results(trace, df, ppc, events_filepath, k):\n",
    "    \"\"\"Analyze and visualize the model results.\"\"\"\n",
    "    # Extract change points\n",
    "    tau_samples = trace.posterior[\"tau\"].values\n",
    "    detected_taus = np.mean(tau_samples, axis=(0, 1)).astype(int)\n",
    "    detected_dates = df['Date'].iloc[detected_taus].values\n",
    "\n",
    "    print(\"\\n📌 Detected Change Points:\")\n",
    "    for i, (idx, date) in enumerate(zip(detected_taus, detected_dates)):\n",
    "        impact = quantify_event_impact(df, idx)\n",
    "        print(f\"\\nChange point {i+1} on {date.date()}:\")\n",
    "        print(f\"  • Mean change: {impact['mean_change']:.4f}\")\n",
    "        print(f\"  • Volatility change: {impact['volatility_change']:.4f}\")\n",
    "        print(f\"  • Price change: {impact['pct_price_change']:.2f}%\")\n",
    "        print(f\"  • Statistical significance (p-value): {impact['t_test_pvalue']:.4f}\")\n",
    "\n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.plot(df['Date'], df['Price'], label='Brent Price')\n",
    "    \n",
    "    for i, (idx, date) in enumerate(zip(detected_taus, detected_dates)):\n",
    "        ax.axvline(x=date, color='red', linestyle='--', alpha=0.7)\n",
    "        ax.text(date, df['Price'].max(), f\"CP {i+1}\", \n",
    "                ha='center', va='bottom', color='red')\n",
    "    \n",
    "    ax.set_title(f\"Brent Oil Price with {k} Detected Change Points\")\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(\"Price (USD)\")\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Model diagnostics\n",
    "    print(\"\\n🔍 Model Diagnostics:\")\n",
    "    print(az.summary(trace, var_names=[\"tau\", \"mu\", \"sigma\"]))\n",
    "    \n",
    "    az.plot_trace(trace, var_names=[\"tau\", \"mu\", \"sigma\"])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        trace, df = bayesian_multiple_change_point_model(\n",
    "            r\"C:\\10x AIMastery\\brent-oil-change-analysis\\data\\raw\\BrentOilPrices.csv\",\n",
    "            r\"C:\\10x AIMastery\\brent-oil-change-analysis\\data\\events.csv\",\n",
    "            k=3\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Execution failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1ab271",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
